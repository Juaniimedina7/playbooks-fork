settings:
  name: "uro: remove uninteresting/duplicate URLs"
  description: "uro extracts and deduplicates URLs from input data by normalizing and filtering them based on predefined rules. It removes duplicates, standardizes formats, and ensures cleaner URL lists for further processing."
  image: python
  author:
    - https://github.com/s0md3v
  gallery:
    - https://files.catbox.moe/n02p8o.png
  example: satori run satori://web/uro.yml -d URL="https://satori.ci/page/1/" -d URL="https://satori.ci/page/2/" --report --output

uro:
  install:
    - pip3 install uro -q --disable-pip-version-check --root-user-action=ignore
    - echo ${{URL}} > urls.txt

  help:
    - uro -h

  test:
    assertReturnCode: 0
    run:
      - cat urls.txt | uro
